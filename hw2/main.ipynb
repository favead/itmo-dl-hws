{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from functools import partial\n",
    "import os\n",
    "from typing import Any, Dict, Callable, List, Tuple\n",
    "import zipfile\n",
    "\n",
    "import gensim.models\n",
    "from navec import Navec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymorphy3\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    global SEED\n",
    "    train_val_df, test_df = train_test_split(\n",
    "        df, test_size=0.2, random_state=SEED, stratify=df[\"label\"].values\n",
    "    )\n",
    "    train_df, val_df = train_test_split(\n",
    "        train_val_df,\n",
    "        test_size=0.2 * df.shape[0] / train_val_df.shape[0],\n",
    "        random_state=SEED,\n",
    "        stratify=train_val_df[\"label\"].values,\n",
    "    )\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    return text.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_df = pd.read_csv(\"../data/hw1/processed_df.csv\")\n",
    "train_df, val_df, test_df = split(tokens_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69234</th>\n",
       "      <td>экономика великобритании году сократится проце...</td>\n",
       "      <td>Экономика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36160</th>\n",
       "      <td>в минобороны россии назвали эффективность амер...</td>\n",
       "      <td>Силовые структуры</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7065</th>\n",
       "      <td>американский боксер мохаммед али госпитализиро...</td>\n",
       "      <td>Спорт</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53795</th>\n",
       "      <td>на окраине мурманска вторник обнаружен подполь...</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63444</th>\n",
       "      <td>пользователь яндекса требует взыскать поискови...</td>\n",
       "      <td>Интернет и СМИ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45054</th>\n",
       "      <td>до конца года будут проведены учебно-боевых пу...</td>\n",
       "      <td>Силовые структуры</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49047</th>\n",
       "      <td>комиссия российской академии наук изучив прете...</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87334</th>\n",
       "      <td>компания ikea выпустила набор рецептов котором...</td>\n",
       "      <td>Интернет и СМИ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44320</th>\n",
       "      <td>в одном мурманских скверов июня года откроют с...</td>\n",
       "      <td>69-я параллель</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51078</th>\n",
       "      <td>военно-воздушные силы году начали разрабатыват...</td>\n",
       "      <td>Наука и техника</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59960 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           filtered_text              label\n",
       "69234  экономика великобритании году сократится проце...          Экономика\n",
       "36160  в минобороны россии назвали эффективность амер...  Силовые структуры\n",
       "7065   американский боксер мохаммед али госпитализиро...              Спорт\n",
       "53795  на окраине мурманска вторник обнаружен подполь...             Россия\n",
       "63444  пользователь яндекса требует взыскать поискови...     Интернет и СМИ\n",
       "...                                                  ...                ...\n",
       "45054  до конца года будут проведены учебно-боевых пу...  Силовые структуры\n",
       "49047  комиссия российской академии наук изучив прете...             Россия\n",
       "87334  компания ikea выпустила набор рецептов котором...     Интернет и СМИ\n",
       "44320  в одном мурманских скверов июня года откроют с...     69-я параллель\n",
       "51078  военно-воздушные силы году начали разрабатыват...    Наука и техника\n",
       "\n",
       "[59960 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение собственных эмбеддингов word2vec:\n",
    "Обоснуем выбор некоторых гиперпараметров.\n",
    "\n",
    "- vector_size - есть внутреннее ощущение, что слишком большие эмбеддинги могут переобучиться на этой задаче, поэтому попробуем начать с 250\n",
    "- window - в задаче классификации текстов нам важно получать контекстную близость, а не синонимическую\n",
    "- min_count - упрощаем обучение уменьшая маловстречаемые слова\n",
    "- sg - Skip Gramm, чтобы быстрее учиться\n",
    "- negative - аналогично, на каждой итерации вместо софтмакса по всему датасету считаем только 5 слов\n",
    "- epochs - чем больше датасет, тем больше эпох можем поставить (обычно 10-50), начнем с 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_df[\"filtered_text\"].apply(tokenize).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"w2v_250_w10_mc5_sg_neg5_ep30\"):\n",
    "    model = gensim.models.Word2Vec.load(\"w2v_250_w10_mc5_sg_neg5_ep30\")\n",
    "else:\n",
    "    model = gensim.models.Word2Vec(\n",
    "        sentences=train_data,\n",
    "        vector_size=250,\n",
    "        window=10,\n",
    "        min_count=5,\n",
    "        sg=1,\n",
    "        negative=5,\n",
    "        epochs=30,\n",
    "        seed=SEED,\n",
    "    )\n",
    "    model.save(\"w2v_250_w10_mc5_sg_neg5_ep30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Экономика | Силовые структуры | Спорт | Россия | Интернет и СМИ | Из жизни | Мир | Наука и техника | Дом | Бывший СССР | Культура | Ценности | Путешествия | Бизнес | Легпром | 69-я параллель | Крым | Культпросвет  | Библиотека\n"
     ]
    }
   ],
   "source": [
    "print(\" | \".join(train_df[\"label\"].unique().tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем оценить качество эмбеддингов, используя самые частотные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ввп', 0.6906951665878296),\n",
       " ('рецессии', 0.6488956212997437),\n",
       " ('рецессию', 0.6266115307807922),\n",
       " ('замедлятся', 0.6121088862419128),\n",
       " ('адаптировалась', 0.5717689394950867),\n",
       " ('экономики', 0.5682619214057922),\n",
       " ('инфляция', 0.5424972176551819),\n",
       " ('экономический', 0.5400095582008362),\n",
       " ('рецессия', 0.5394936203956604),\n",
       " ('рецессией', 0.5338839292526245)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"экономика\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('нигерийского', 0.1339004635810852),\n",
       " ('прицельный', 0.12875449657440186),\n",
       " ('рыжего', 0.11170051246881485),\n",
       " ('палестинца', 0.11158581078052521),\n",
       " ('стрельбой', 0.10589572787284851),\n",
       " ('четверым', 0.10377943515777588),\n",
       " ('гаражного', 0.10017924010753632),\n",
       " ('пятерым', 0.09932998567819595),\n",
       " ('самары', 0.09752027690410614),\n",
       " ('красноярска', 0.09594501554965973)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(negative=[\"экономика\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('гу', 0.7301331162452698),\n",
       " ('милиции', 0.6089017391204834),\n",
       " ('следственного', 0.6055797934532166),\n",
       " ('главка', 0.6005496382713318),\n",
       " ('внутренних', 0.5966971516609192),\n",
       " ('увд', 0.5913692712783813),\n",
       " ('оперативно-розыскного', 0.5893971920013428),\n",
       " ('говд', 0.5781435966491699),\n",
       " ('гувд', 0.5723111629486084),\n",
       " ('фсб', 0.5708879232406616)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"мвд\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ямайка', 0.1073177233338356),\n",
       " ('дилан', 0.10620534420013428),\n",
       " ('melissa', 0.10451147705316544),\n",
       " ('консультировал', 0.10422379523515701),\n",
       " ('здоровой', 0.10061188787221909),\n",
       " ('подниматься', 0.1005881130695343),\n",
       " ('фазе', 0.09912239015102386),\n",
       " ('высказывают', 0.095782071352005),\n",
       " ('lake', 0.09563589841127396),\n",
       " ('охлаждении', 0.09526385366916656)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(negative=[\"мвд\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('баскетбол', 0.5135613679885864),\n",
       " ('футболистов', 0.4858241677284241),\n",
       " ('атлетику', 0.48419076204299927),\n",
       " ('матч', 0.47358715534210205),\n",
       " ('играть', 0.47240549325942993),\n",
       " ('легии', 0.4598545730113983),\n",
       " ('футбольный', 0.45508161187171936),\n",
       " ('болельщики', 0.4550151824951172),\n",
       " ('расслабляться', 0.4545561671257019),\n",
       " ('футбола', 0.45173168182373047)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"футбол\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('фгупов', 0.12461049109697342),\n",
       " ('сертификации', 0.12004587799310684),\n",
       " ('подлежат', 0.1166456788778305),\n",
       " ('вывезены', 0.11573202162981033),\n",
       " ('имелся', 0.11476853489875793),\n",
       " ('согласованию', 0.11053688079118729),\n",
       " ('печатью', 0.11017366498708725),\n",
       " ('сложностях', 0.10659559071063995),\n",
       " ('отозвало', 0.10580680519342422),\n",
       " ('позволяло', 0.10374383628368378)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(negative=[\"футбол\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выглядит так, что ключевые слова разделены по категориям, поэтому параметры подобраны достаточно хорошо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\n",
    "    \"https://vectors.nlpl.eu/repository/20/184.zip\", \"news_upos_skipgram_300_5_2019.zip\"\n",
    ")\n",
    "zip_path = \"news_upos_skipgram_300_5_2019.zip\"\n",
    "extract_folder = \"news_upos_skipgram_300_5_2019\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(extract_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rusvec_model_path = \"news_upos_skipgram_300_5_2019/model.bin\"\n",
    "rusvec_model = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "    rusvec_model_path, binary=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('гумвд_NOUN', 0.4122755229473114),\n",
       " ('уфсб_NOUN', 0.41181737184524536),\n",
       " ('гувд_NOUN', 0.392577588558197),\n",
       " ('адриан::ранкин-гэллоуэй_PROPN', 0.3685126304626465),\n",
       " ('алиевой_NOUN', 0.3653308153152466),\n",
       " ('возражалийский_ADJ', 0.3638455271720886),\n",
       " ('мчс::россия::раиса::копырина_PROPN', 0.3625434935092926),\n",
       " ('амра::юзбеков_PROPN', 0.36013513803482056),\n",
       " ('республиканца_NOUN', 0.3595658838748932),\n",
       " ('мвд::россия_PROPN', 0.35692664980888367)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rusvec_model.most_similar(\"мвд_NOUN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И теперь из navec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.yandexcloud.net/natasha-navec/packs/navec_hudlit_v1_12B_500K_300d_100q.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"navec_hudlit_v1_12B_500K_300d_100q.tar\"\n",
    "navec_model = Navec.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 0\n",
    "    return np.dot(vec1, vec2) / (norm1 * norm2)\n",
    "\n",
    "\n",
    "def ineffective_most_similiar(\n",
    "    navec_model: Navec, word: str, top_n: int = 10\n",
    ") -> List[Tuple[str, float]]:\n",
    "    if word not in navec_model:\n",
    "        raise ValueError(f\"Слова {word} нет в модели\")\n",
    "\n",
    "    word_vector = navec_model[word]\n",
    "    similarities = {}\n",
    "    for other_word in navec_model.vocab.words:\n",
    "        other_vector = navec_model[other_word]\n",
    "        other_norm = np.linalg.norm(other_vector)\n",
    "\n",
    "        if other_norm == 0:\n",
    "            continue\n",
    "\n",
    "        similarities[other_word] = cosine_similarity(word_vector, other_vector)\n",
    "\n",
    "    return sorted(similarities.items(), key=lambda x: x[1], reverse=True)[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('мвд', 1.0),\n",
       " ('фсб', 0.76623964),\n",
       " ('кгб', 0.7264482),\n",
       " ('мгб', 0.69483584),\n",
       " ('гувд', 0.68139136),\n",
       " ('нквд', 0.6729191),\n",
       " ('госбезопасности', 0.6632358),\n",
       " ('увд', 0.6568187),\n",
       " ('гру', 0.64401966),\n",
       " ('прокуратуры', 0.6382184)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ineffective_most_similiar(navec_model, \"мвд\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = navec_model.pq.dim\n",
    "gensim_from_navec = gensim.models.KeyedVectors(vector_size)\n",
    "words, vectors = [], []\n",
    "for word in navec_model.vocab.words:\n",
    "    vec = navec_model[word]\n",
    "    if np.linalg.norm(vec) > 0:\n",
    "        words.append(word)\n",
    "        vectors.append(vec)\n",
    "\n",
    "gensim_from_navec.add_vectors(words, np.array(vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть ощущение, что вектора из navec и rusvector больше склонны показывать функциональную близость - т.е. слова, которые являются почти синонимами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим на каждом виде эмбеддингов модель логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(\n",
    "    data: pd.DataFrame,\n",
    "    emb_model: gensim.models.Word2Vec,\n",
    "    use_tag: bool = False,\n",
    "    is_kv: bool = False,\n",
    "    emb_dim: int = 300,\n",
    ") -> np.ndarray:\n",
    "    if use_tag:\n",
    "        morph = pymorphy3.MorphAnalyzer()\n",
    "    X = np.empty((0, emb_dim))\n",
    "    for text in data[\"filtered_text\"].values:\n",
    "        if use_tag:\n",
    "            pos_tags = [morph.parse(word)[0].tag.POS for word in text.split(\" \")]\n",
    "        avg_emb = np.empty((0, emb_dim))\n",
    "        for i, token in enumerate(text.split(\" \")):\n",
    "            token = f\"{token}_{pos_tags[i]}\" if use_tag else token\n",
    "            embs_storage = emb_model if is_kv else emb_model.wv\n",
    "            if token in embs_storage:\n",
    "                emb = embs_storage[token]\n",
    "                avg_emb = np.vstack((avg_emb, emb))\n",
    "        if len(avg_emb) > 0:\n",
    "            avg_emb = np.mean(avg_emb, axis=0).reshape(1, emb_dim)\n",
    "        else:\n",
    "            avg_emb = np.zeros((1, emb_dim))\n",
    "        X = np.vstack((X, avg_emb))\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_train_features = create_features(train_df, model, emb_dim=250)\n",
    "rusvec_train_features = create_features(\n",
    "    train_df, rusvec_model, use_tag=True, is_kv=True, emb_dim=300\n",
    ")\n",
    "navec_train_features = create_features(\n",
    "    train_df, gensim_from_navec, is_kv=True, emb_dim=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fpath, features in zip(\n",
    "    [\"custom_train\", \"rusvec_train\", \"navec_train\"],\n",
    "    [custom_train_features, rusvec_train_features, navec_train_features],\n",
    "):\n",
    "    with open(f\"../data/hw2/{fpath}.npy\", \"wb\") as f:\n",
    "        np.save(f, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/hw2/custom_train.npy\", \"rb\") as f:\n",
    "    custom_train_features = np.load(f)\n",
    "with open(\"../data/hw2/rusvec_train.npy\", \"rb\") as f:\n",
    "    rusvec_train_features = np.load(f)\n",
    "with open(\"../data/hw2/navec_train.npy\", \"rb\") as f:\n",
    "    navec_train_features = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_val_features = create_features(val_df, model, emb_dim=250)\n",
    "rusvec_val_features = create_features(\n",
    "    val_df, rusvec_model, use_tag=True, is_kv=True, emb_dim=300\n",
    ")\n",
    "navec_val_features = create_features(val_df, gensim_from_navec, is_kv=True, emb_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fpath, features in zip(\n",
    "    [\"custom_val\", \"rusvec_val\", \"navec_val\"],\n",
    "    [custom_val_features, rusvec_val_features, navec_val_features],\n",
    "):\n",
    "    with open(f\"../data/hw2/{fpath}.npy\", \"wb\") as f:\n",
    "        np.save(f, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/hw2/custom_val.npy\", \"rb\") as f:\n",
    "    custom_val_features = np.load(f)\n",
    "with open(\"../data/hw2/rusvec_val.npy\", \"rb\") as f:\n",
    "    rusvec_val_features = np.load(f)\n",
    "with open(\"../data/hw2/navec_val.npy\", \"rb\") as f:\n",
    "    navec_val_features = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_test_features = create_features(test_df, model, emb_dim=250)\n",
    "rusvec_test_features = create_features(\n",
    "    test_df, rusvec_model, use_tag=True, is_kv=True, emb_dim=300\n",
    ")\n",
    "navec_test_features = create_features(\n",
    "    test_df, gensim_from_navec, is_kv=True, emb_dim=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fpath, features in zip(\n",
    "    [\"custom_test\", \"rusvec_test\", \"navec_test\"],\n",
    "    [custom_test_features, rusvec_test_features, navec_test_features],\n",
    "):\n",
    "    with open(f\"../data/hw2/{fpath}.npy\", \"wb\") as f:\n",
    "        np.save(f, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/hw2/custom_test.npy\", \"rb\") as f:\n",
    "    custom_test_features = np.load(f)\n",
    "with open(\"../data/hw2/rusvec_test.npy\", \"rb\") as f:\n",
    "    rusvec_test_features = np.load(f)\n",
    "with open(\"../data/hw2/navec_test.npy\", \"rb\") as f:\n",
    "    navec_test_features = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logreg(X: np.ndarray, y: np.ndarray) -> LogisticRegression:\n",
    "    logreg = LogisticRegression(max_iter=2000)\n",
    "    logreg.fit(X, y)\n",
    "    return logreg\n",
    "\n",
    "\n",
    "y = train_df[\"label\"].values\n",
    "custom_fs_logreg = train_logreg(custom_train_features, y)\n",
    "rusvec_fs_logreg = train_logreg(rusvec_train_features, y)\n",
    "navec_fs_logreg = train_logreg(navec_train_features, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   69-я параллель       1.00      0.06      0.11        35\n",
      "       Библиотека       0.00      0.00      0.00         2\n",
      "           Бизнес       0.65      0.15      0.25       200\n",
      "      Бывший СССР       0.82      0.76      0.79      1444\n",
      "              Дом       0.84      0.74      0.79       588\n",
      "         Из жизни       0.64      0.59      0.61       747\n",
      "   Интернет и СМИ       0.76      0.68      0.72      1209\n",
      "             Крым       0.00      0.00      0.00        18\n",
      "    Культпросвет        0.00      0.00      0.00         9\n",
      "         Культура       0.87      0.86      0.87      1455\n",
      "          Легпром       0.00      0.00      0.00         3\n",
      "              Мир       0.77      0.85      0.81      3697\n",
      "  Наука и техника       0.82      0.81      0.82      1434\n",
      "      Путешествия       0.74      0.45      0.56       174\n",
      "           Россия       0.75      0.84      0.79      4338\n",
      "Силовые структуры       0.65      0.28      0.39       530\n",
      "            Спорт       0.97      0.96      0.97      1743\n",
      "         Ценности       0.87      0.74      0.80       210\n",
      "        Экономика       0.81      0.86      0.83      2151\n",
      "\n",
      "         accuracy                           0.80     19987\n",
      "        macro avg       0.63      0.51      0.53     19987\n",
      "     weighted avg       0.79      0.80      0.79     19987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "custom_vp = custom_fs_logreg.predict(custom_val_features)\n",
    "print(classification_report(val_df[\"label\"].values, custom_vp, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   69-я параллель       0.45      0.14      0.22        35\n",
      "       Библиотека       0.00      0.00      0.00         2\n",
      "           Бизнес       0.42      0.10      0.16       200\n",
      "      Бывший СССР       0.71      0.61      0.65      1444\n",
      "              Дом       0.73      0.69      0.71       588\n",
      "         Из жизни       0.55      0.46      0.50       747\n",
      "   Интернет и СМИ       0.63      0.52      0.57      1209\n",
      "             Крым       0.00      0.00      0.00        18\n",
      "    Культпросвет        0.00      0.00      0.00         9\n",
      "         Культура       0.81      0.81      0.81      1455\n",
      "          Легпром       0.00      0.00      0.00         3\n",
      "              Мир       0.70      0.78      0.74      3697\n",
      "  Наука и техника       0.72      0.74      0.73      1434\n",
      "      Путешествия       0.55      0.36      0.43       174\n",
      "           Россия       0.69      0.78      0.73      4338\n",
      "Силовые структуры       0.49      0.20      0.28       530\n",
      "            Спорт       0.95      0.95      0.95      1743\n",
      "         Ценности       0.78      0.64      0.70       210\n",
      "        Экономика       0.74      0.81      0.77      2151\n",
      "\n",
      "         accuracy                           0.72     19987\n",
      "        macro avg       0.52      0.45      0.47     19987\n",
      "     weighted avg       0.71      0.72      0.71     19987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rusvec_vp = rusvec_fs_logreg.predict(rusvec_val_features)\n",
    "print(classification_report(val_df[\"label\"].values, rusvec_vp, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   69-я параллель       0.50      0.03      0.05        35\n",
      "       Библиотека       0.00      0.00      0.00         2\n",
      "           Бизнес       0.64      0.12      0.19       200\n",
      "      Бывший СССР       0.75      0.70      0.73      1444\n",
      "              Дом       0.79      0.72      0.75       588\n",
      "         Из жизни       0.62      0.56      0.59       747\n",
      "   Интернет и СМИ       0.71      0.64      0.67      1209\n",
      "             Крым       0.00      0.00      0.00        18\n",
      "    Культпросвет        0.00      0.00      0.00         9\n",
      "         Культура       0.85      0.85      0.85      1455\n",
      "          Легпром       0.00      0.00      0.00         3\n",
      "              Мир       0.76      0.83      0.79      3697\n",
      "  Наука и техника       0.80      0.80      0.80      1434\n",
      "      Путешествия       0.63      0.43      0.51       174\n",
      "           Россия       0.73      0.81      0.77      4338\n",
      "Силовые структуры       0.54      0.23      0.32       530\n",
      "            Спорт       0.96      0.95      0.96      1743\n",
      "         Ценности       0.79      0.73      0.76       210\n",
      "        Экономика       0.78      0.84      0.80      2151\n",
      "\n",
      "         accuracy                           0.77     19987\n",
      "        macro avg       0.57      0.49      0.50     19987\n",
      "     weighted avg       0.76      0.77      0.76     19987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "navec_vp = navec_fs_logreg.predict(navec_val_features)\n",
    "print(classification_report(val_df[\"label\"].values, navec_vp, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кастомные эмбедиднги показали лучший результат по всем средним метрикам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем применить веса tf-idf для эмбеддингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_param_grid = {\"min_df\": [500, 1000, 5000], \"max_df\": [0.8, 0.9, 0.95]}\n",
    "param_combs = list(product(tf_idf_param_grid[\"min_df\"], tf_idf_param_grid[\"max_df\"]))\n",
    "param_combs = [{\"min_df\": comb[0], \"max_df\": comb[1]} for comb in param_combs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_features(\n",
    "    weights: np.ndarray,\n",
    "    emb_size: int,\n",
    "    texts: np.ndarray,\n",
    "    model: gensim.models.Word2Vec,\n",
    "    tf_idf_vectorizer: TfidfVectorizer,\n",
    ") -> np.ndarray:\n",
    "    vocabulary = tf_idf_vectorizer.vocabulary_\n",
    "    embeddings = np.zeros((len(texts), emb_size))\n",
    "\n",
    "    for i, text in enumerate(texts):\n",
    "        tokens = text.split()\n",
    "        token_weights = []\n",
    "        token_embs = []\n",
    "\n",
    "        for token in tokens:\n",
    "            word_id = vocabulary.get(token)\n",
    "            if word_id is None or weights[i, word_id] == 0:\n",
    "                continue\n",
    "            try:\n",
    "                emb = model.wv.get_vector(token)\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "            token_weights.append(weights[i, word_id])\n",
    "            token_embs.append(emb * weights[i, word_id])\n",
    "\n",
    "        if token_embs:\n",
    "            embeddings[i] = np.average(token_embs, axis=0, weights=token_weights)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def find_hyperparams(\n",
    "    model: gensim.models.Word2Vec,\n",
    "    param_grid: Dict[str, Any],\n",
    "    emb_size: int = 250,\n",
    "    metric_funk: Callable = f1_score,\n",
    "    more_is_better: bool = True,\n",
    ") -> Dict[str, Any]:\n",
    "    param_combs = list(product(*param_grid.values()))\n",
    "    param_combs = [\n",
    "        {key: val for key, val in zip(param_grid.keys(), comb)} for comb in param_combs\n",
    "    ]\n",
    "    results = []\n",
    "    train_y = train_df[\"label\"].values\n",
    "    val_y = val_df[\"label\"].values\n",
    "    for params in tqdm.tqdm(param_combs):\n",
    "        tf_idf_vectorizer = TfidfVectorizer(**params)\n",
    "        train_tfidfw = tf_idf_vectorizer.fit_transform(train_df[\"filtered_text\"].values)\n",
    "        val_tfidfw = tf_idf_vectorizer.transform(val_df[\"filtered_text\"].values)\n",
    "        train_X = get_weighted_features(\n",
    "            train_tfidfw,\n",
    "            emb_size,\n",
    "            train_df[\"filtered_text\"].values,\n",
    "            model,\n",
    "            tf_idf_vectorizer,\n",
    "        )\n",
    "        val_X = get_weighted_features(\n",
    "            val_tfidfw,\n",
    "            emb_size,\n",
    "            val_df[\"filtered_text\"].values,\n",
    "            model,\n",
    "            tf_idf_vectorizer,\n",
    "        )\n",
    "        logreg = LogisticRegression(max_iter=3500)\n",
    "        logreg.fit(train_X, train_y)\n",
    "        val_preds = logreg.predict(val_X)\n",
    "        criteria = metric_funk(val_y, val_preds)\n",
    "        results.append({**params, \"criteria\": criteria})\n",
    "    best_params = list(\n",
    "        sorted(results, key=lambda x: x[\"criteria\"], reverse=more_is_better)\n",
    "    )[0]\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [21:45<00:00, 145.10s/it]\n"
     ]
    }
   ],
   "source": [
    "best_params = find_hyperparams(\n",
    "    model, tf_idf_param_grid, 250, partial(f1_score, average=\"macro\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_data = (\n",
    "    train_df[\"filtered_text\"].values.tolist() + val_df[\"filtered_text\"].values.tolist()\n",
    ")\n",
    "train_val_y = train_df[\"label\"].values.tolist() + val_df[\"label\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_params = {**best_params}\n",
    "del tf_idf_params[\"criteria\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=3000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=3000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=3000)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vect = TfidfVectorizer(**tf_idf_params)\n",
    "train_val_weights = tf_idf_vect.fit_transform(train_val_data)\n",
    "train_val_features = get_weighted_features(\n",
    "    train_val_weights, 250, train_val_data, model, tf_idf_vect\n",
    ")\n",
    "ctv_w2v_ifidf_logreg = LogisticRegression(max_iter=3000)\n",
    "ctv_w2v_ifidf_logreg.fit(train_val_features, train_val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_weights = tf_idf_vect.transform(test_df[\"filtered_text\"].values)\n",
    "test_features = get_weighted_features(\n",
    "    test_weights,\n",
    "    250,\n",
    "    test_df[\"filtered_text\"].values,\n",
    "    model,\n",
    "    tf_idf_vect\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   69-я параллель       0.00      0.00      0.00        34\n",
      "       Библиотека       0.00      0.00      0.00         2\n",
      "           Бизнес       0.17      0.01      0.01       200\n",
      "      Бывший СССР       0.73      0.44      0.55      1444\n",
      "              Дом       0.78      0.55      0.64       588\n",
      "         Из жизни       0.47      0.22      0.30       747\n",
      "   Интернет и СМИ       0.63      0.44      0.52      1208\n",
      "             Крым       0.00      0.00      0.00        18\n",
      "    Культпросвет        0.00      0.00      0.00         9\n",
      "         Культура       0.72      0.70      0.71      1456\n",
      "          Легпром       0.00      0.00      0.00         3\n",
      "              Мир       0.61      0.78      0.68      3697\n",
      "  Наука и техника       0.68      0.69      0.69      1435\n",
      "      Путешествия       0.71      0.06      0.11       173\n",
      "           Россия       0.59      0.77      0.67      4338\n",
      "Силовые структуры       0.48      0.04      0.08       530\n",
      "            Спорт       0.91      0.86      0.88      1743\n",
      "         Ценности       0.83      0.36      0.50       210\n",
      "        Экономика       0.67      0.77      0.72      2152\n",
      "\n",
      "         accuracy                           0.66     19987\n",
      "        macro avg       0.47      0.35      0.37     19987\n",
      "     weighted avg       0.65      0.66      0.64     19987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_y = test_df[\"label\"].values\n",
    "test_preds = ctv_w2v_ifidf_logreg.predict(test_features)\n",
    "print(classification_report(test_y, test_preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним с термя моделями, которые были получены ранее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   69-я параллель       0.86      0.18      0.29        34\n",
      "       Библиотека       0.00      0.00      0.00         2\n",
      "           Бизнес       0.59      0.12      0.19       200\n",
      "      Бывший СССР       0.81      0.79      0.80      1444\n",
      "              Дом       0.87      0.75      0.81       588\n",
      "         Из жизни       0.61      0.51      0.56       747\n",
      "   Интернет и СМИ       0.73      0.67      0.70      1208\n",
      "             Крым       0.00      0.00      0.00        18\n",
      "    Культпросвет        0.00      0.00      0.00         9\n",
      "         Культура       0.86      0.87      0.86      1456\n",
      "          Легпром       0.00      0.00      0.00         3\n",
      "              Мир       0.77      0.84      0.81      3697\n",
      "  Наука и техника       0.83      0.81      0.82      1435\n",
      "      Путешествия       0.76      0.56      0.65       173\n",
      "           Россия       0.74      0.83      0.78      4338\n",
      "Силовые структуры       0.65      0.26      0.37       530\n",
      "            Спорт       0.97      0.96      0.96      1743\n",
      "         Ценности       0.92      0.76      0.83       210\n",
      "        Экономика       0.81      0.87      0.84      2152\n",
      "\n",
      "         accuracy                           0.79     19987\n",
      "        macro avg       0.62      0.51      0.54     19987\n",
      "     weighted avg       0.79      0.79      0.79     19987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "custom_tp = custom_fs_logreg.predict(custom_test_features)\n",
    "print(classification_report(test_y, custom_tp, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   69-я параллель       0.71      0.29      0.42        34\n",
      "       Библиотека       0.00      0.00      0.00         2\n",
      "           Бизнес       0.45      0.09      0.15       200\n",
      "      Бывший СССР       0.72      0.64      0.68      1444\n",
      "              Дом       0.76      0.70      0.73       588\n",
      "         Из жизни       0.51      0.40      0.45       747\n",
      "   Интернет и СМИ       0.61      0.54      0.57      1208\n",
      "             Крым       0.33      0.11      0.17        18\n",
      "    Культпросвет        0.00      0.00      0.00         9\n",
      "         Культура       0.79      0.81      0.80      1456\n",
      "          Легпром       0.00      0.00      0.00         3\n",
      "              Мир       0.71      0.78      0.74      3697\n",
      "  Наука и техника       0.73      0.74      0.74      1435\n",
      "      Путешествия       0.58      0.35      0.43       173\n",
      "           Россия       0.69      0.78      0.73      4338\n",
      "Силовые структуры       0.43      0.18      0.25       530\n",
      "            Спорт       0.95      0.94      0.95      1743\n",
      "         Ценности       0.83      0.65      0.73       210\n",
      "        Экономика       0.74      0.80      0.77      2152\n",
      "\n",
      "         accuracy                           0.72     19987\n",
      "        macro avg       0.55      0.46      0.49     19987\n",
      "     weighted avg       0.71      0.72      0.71     19987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rusvec_tp = rusvec_fs_logreg.predict(rusvec_test_features)\n",
    "print(classification_report(test_y, rusvec_tp, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   69-я параллель       0.86      0.18      0.29        34\n",
      "       Библиотека       0.00      0.00      0.00         2\n",
      "           Бизнес       0.41      0.10      0.15       200\n",
      "      Бывший СССР       0.76      0.70      0.73      1444\n",
      "              Дом       0.83      0.76      0.79       588\n",
      "         Из жизни       0.58      0.51      0.54       747\n",
      "   Интернет и СМИ       0.67      0.62      0.65      1208\n",
      "             Крым       0.00      0.00      0.00        18\n",
      "    Культпросвет        0.00      0.00      0.00         9\n",
      "         Культура       0.84      0.86      0.85      1456\n",
      "          Легпром       0.00      0.00      0.00         3\n",
      "              Мир       0.76      0.81      0.78      3697\n",
      "  Наука и техника       0.78      0.80      0.79      1435\n",
      "      Путешествия       0.61      0.50      0.55       173\n",
      "           Россия       0.72      0.80      0.76      4338\n",
      "Силовые структуры       0.53      0.20      0.29       530\n",
      "            Спорт       0.95      0.94      0.95      1743\n",
      "         Ценности       0.82      0.70      0.76       210\n",
      "        Экономика       0.78      0.83      0.81      2152\n",
      "\n",
      "         accuracy                           0.76     19987\n",
      "        macro avg       0.57      0.49      0.51     19987\n",
      "     weighted avg       0.76      0.76      0.75     19987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "navec_tp = navec_fs_logreg.predict(navec_test_features)\n",
    "print(classification_report(test_y, navec_tp, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интересно, что в итоге наилучшее качество было получено через обычное усреднение без учета tf-idf..\n",
    "\n",
    "Но это хотя бо соотносится с результатами первой ДЗ, где tf-idf показал себя хуже, чем count_vectorizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
