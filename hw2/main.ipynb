{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import zipfile\n",
    "\n",
    "import gensim.models\n",
    "from navec import Navec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymorphy3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    global SEED\n",
    "    train_val_df, test_df = train_test_split(\n",
    "        df, test_size=0.2, random_state=SEED, stratify=df[\"label\"].values\n",
    "    )\n",
    "    train_df, val_df = train_test_split(\n",
    "        train_val_df,\n",
    "        test_size=0.2 * df.shape[0] / train_val_df.shape[0],\n",
    "        random_state=SEED,\n",
    "        stratify=train_val_df[\"label\"].values,\n",
    "    )\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    return text.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_df = pd.read_csv(\"../data/hw1/processed_df.csv\")\n",
    "train_df, val_df, test_df = split(tokens_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69234</th>\n",
       "      <td>экономика великобритании году сократится проце...</td>\n",
       "      <td>Экономика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36160</th>\n",
       "      <td>в минобороны россии назвали эффективность амер...</td>\n",
       "      <td>Силовые структуры</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7065</th>\n",
       "      <td>американский боксер мохаммед али госпитализиро...</td>\n",
       "      <td>Спорт</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53795</th>\n",
       "      <td>на окраине мурманска вторник обнаружен подполь...</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63444</th>\n",
       "      <td>пользователь яндекса требует взыскать поискови...</td>\n",
       "      <td>Интернет и СМИ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45054</th>\n",
       "      <td>до конца года будут проведены учебно-боевых пу...</td>\n",
       "      <td>Силовые структуры</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49047</th>\n",
       "      <td>комиссия российской академии наук изучив прете...</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87334</th>\n",
       "      <td>компания ikea выпустила набор рецептов котором...</td>\n",
       "      <td>Интернет и СМИ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44320</th>\n",
       "      <td>в одном мурманских скверов июня года откроют с...</td>\n",
       "      <td>69-я параллель</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51078</th>\n",
       "      <td>военно-воздушные силы году начали разрабатыват...</td>\n",
       "      <td>Наука и техника</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59960 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           filtered_text              label\n",
       "69234  экономика великобритании году сократится проце...          Экономика\n",
       "36160  в минобороны россии назвали эффективность амер...  Силовые структуры\n",
       "7065   американский боксер мохаммед али госпитализиро...              Спорт\n",
       "53795  на окраине мурманска вторник обнаружен подполь...             Россия\n",
       "63444  пользователь яндекса требует взыскать поискови...     Интернет и СМИ\n",
       "...                                                  ...                ...\n",
       "45054  до конца года будут проведены учебно-боевых пу...  Силовые структуры\n",
       "49047  комиссия российской академии наук изучив прете...             Россия\n",
       "87334  компания ikea выпустила набор рецептов котором...     Интернет и СМИ\n",
       "44320  в одном мурманских скверов июня года откроют с...     69-я параллель\n",
       "51078  военно-воздушные силы году начали разрабатыват...    Наука и техника\n",
       "\n",
       "[59960 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение собственных эмбеддингов word2vec:\n",
    "Обоснуем выбор некоторых гиперпараметров.\n",
    "\n",
    "- vector_size - есть внутреннее ощущение, что слишком большие эмбеддинги могут переобучиться на этой задаче, поэтому попробуем начать с 250\n",
    "- window - в задаче классификации текстов нам важно получать контекстную близость, а не синонимическую\n",
    "- min_count - упрощаем обучение уменьшая маловстречаемые слова\n",
    "- sg - Skip Gramm, чтобы быстрее учиться\n",
    "- negative - аналогично, на каждой итерации вместо софтмакса по всему датасету считаем только 5 слов\n",
    "- epochs - чем больше датасет, тем больше эпох можем поставить (обычно 10-50), начнем с 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_df[\"filtered_text\"].apply(tokenize).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    sentences=train_data,\n",
    "    vector_size=250,\n",
    "    window=10,\n",
    "    min_count=5,\n",
    "    sg=1,\n",
    "    negative=5,\n",
    "    epochs=30,\n",
    "    seed=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"w2v_250_w10_mc5_sg_neg5_ep30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Экономика | Силовые структуры | Спорт | Россия | Интернет и СМИ | Из жизни | Мир | Наука и техника | Дом | Бывший СССР | Культура | Ценности | Путешествия | Бизнес | Легпром | 69-я параллель | Крым | Культпросвет  | Библиотека\n"
     ]
    }
   ],
   "source": [
    "print(\" | \".join(train_df[\"label\"].unique().tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем оценить качество эмбеддингов, используя самые частотные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ввп', 0.6906951665878296),\n",
       " ('рецессии', 0.6488956212997437),\n",
       " ('рецессию', 0.6266115307807922),\n",
       " ('замедлятся', 0.6121088862419128),\n",
       " ('адаптировалась', 0.5717689394950867),\n",
       " ('экономики', 0.5682619214057922),\n",
       " ('инфляция', 0.5424972176551819),\n",
       " ('экономический', 0.5400095582008362),\n",
       " ('рецессия', 0.5394936203956604),\n",
       " ('рецессией', 0.5338839292526245)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"экономика\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('нигерийского', 0.1339004635810852),\n",
       " ('прицельный', 0.12875449657440186),\n",
       " ('рыжего', 0.11170051246881485),\n",
       " ('палестинца', 0.11158581078052521),\n",
       " ('стрельбой', 0.10589572787284851),\n",
       " ('четверым', 0.10377943515777588),\n",
       " ('гаражного', 0.10017924010753632),\n",
       " ('пятерым', 0.09932998567819595),\n",
       " ('самары', 0.09752027690410614),\n",
       " ('красноярска', 0.09594501554965973)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(negative=[\"экономика\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('гу', 0.7301331162452698),\n",
       " ('милиции', 0.6089017391204834),\n",
       " ('следственного', 0.6055797934532166),\n",
       " ('главка', 0.6005496382713318),\n",
       " ('внутренних', 0.5966971516609192),\n",
       " ('увд', 0.5913692712783813),\n",
       " ('оперативно-розыскного', 0.5893971920013428),\n",
       " ('говд', 0.5781435966491699),\n",
       " ('гувд', 0.5723111629486084),\n",
       " ('фсб', 0.5708879232406616)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"мвд\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ямайка', 0.1073177233338356),\n",
       " ('дилан', 0.10620534420013428),\n",
       " ('melissa', 0.10451147705316544),\n",
       " ('консультировал', 0.10422379523515701),\n",
       " ('здоровой', 0.10061188787221909),\n",
       " ('подниматься', 0.1005881130695343),\n",
       " ('фазе', 0.09912239015102386),\n",
       " ('высказывают', 0.095782071352005),\n",
       " ('lake', 0.09563589841127396),\n",
       " ('охлаждении', 0.09526385366916656)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(negative=[\"мвд\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('баскетбол', 0.5135613679885864),\n",
       " ('футболистов', 0.4858241677284241),\n",
       " ('атлетику', 0.48419076204299927),\n",
       " ('матч', 0.47358715534210205),\n",
       " ('играть', 0.47240549325942993),\n",
       " ('легии', 0.4598545730113983),\n",
       " ('футбольный', 0.45508161187171936),\n",
       " ('болельщики', 0.4550151824951172),\n",
       " ('расслабляться', 0.4545561671257019),\n",
       " ('футбола', 0.45173168182373047)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"футбол\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('фгупов', 0.12461049109697342),\n",
       " ('сертификации', 0.12004587799310684),\n",
       " ('подлежат', 0.1166456788778305),\n",
       " ('вывезены', 0.11573202162981033),\n",
       " ('имелся', 0.11476853489875793),\n",
       " ('согласованию', 0.11053688079118729),\n",
       " ('печатью', 0.11017366498708725),\n",
       " ('сложностях', 0.10659559071063995),\n",
       " ('отозвало', 0.10580680519342422),\n",
       " ('позволяло', 0.10374383628368378)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(negative=[\"футбол\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выглядит так, что ключевые слова разделены по категориям, поэтому параметры подобраны достаточно хорошо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('news_upos_skipgram_300_5_2019.zip',\n",
       " <http.client.HTTPMessage at 0x72fca26c6ed0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\n",
    "    \"https://vectors.nlpl.eu/repository/20/184.zip\", \"news_upos_skipgram_300_5_2019.zip\"\n",
    ")\n",
    "zip_path = \"news_upos_skipgram_300_5_2019.zip\"\n",
    "extract_folder = \"news_upos_skipgram_300_5_2019\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(extract_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "rusvec_model_path = \"news_upos_skipgram_300_5_2019/model.bin\"\n",
    "rusvec_model = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "    rusvec_model_path, binary=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('гумвд_NOUN', 0.4122755229473114),\n",
       " ('уфсб_NOUN', 0.41181737184524536),\n",
       " ('гувд_NOUN', 0.392577588558197),\n",
       " ('адриан::ранкин-гэллоуэй_PROPN', 0.3685126304626465),\n",
       " ('алиевой_NOUN', 0.3653308153152466),\n",
       " ('возражалийский_ADJ', 0.3638455271720886),\n",
       " ('мчс::россия::раиса::копырина_PROPN', 0.3625434935092926),\n",
       " ('амра::юзбеков_PROPN', 0.36013513803482056),\n",
       " ('республиканца_NOUN', 0.3595658838748932),\n",
       " ('мвд::россия_PROPN', 0.35692664980888367)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rusvec_model.most_similar(\"мвд_NOUN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И теперь из navec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-13 23:01:42--  https://storage.yandexcloud.net/natasha-navec/packs/navec_hudlit_v1_12B_500K_300d_100q.tar\n",
      "Распознаётся storage.yandexcloud.net (storage.yandexcloud.net)… 213.180.193.243, 2a02:6b8::1d9\n",
      "Подключение к storage.yandexcloud.net (storage.yandexcloud.net)|213.180.193.243|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 53012480 (51M) [application/x-tar]\n",
      "Сохранение в: ‘navec_hudlit_v1_12B_500K_300d_100q.tar’\n",
      "\n",
      "navec_hudlit_v1_12B 100%[===================>]  50,56M  10,9MB/s    за 5,1s    \n",
      "\n",
      "2025-03-13 23:01:47 (9,99 MB/s) - ‘navec_hudlit_v1_12B_500K_300d_100q.tar’ сохранён [53012480/53012480]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.yandexcloud.net/natasha-navec/packs/navec_hudlit_v1_12B_500K_300d_100q.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"navec_hudlit_v1_12B_500K_300d_100q.tar\"\n",
    "navec_model = Navec.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 0\n",
    "    return np.dot(vec1, vec2) / (norm1 * norm2)\n",
    "\n",
    "\n",
    "def ineffective_most_similiar(\n",
    "    navec_model: Navec, word: str, top_n: int = 10\n",
    ") -> List[Tuple[str, float]]:\n",
    "    if word not in navec_model:\n",
    "        raise ValueError(f\"Слова {word} нет в модели\")\n",
    "\n",
    "    word_vector = navec_model[word]\n",
    "    similarities = {}\n",
    "    for other_word in navec_model.vocab.words:\n",
    "        other_vector = navec_model[other_word]\n",
    "        other_norm = np.linalg.norm(other_vector)\n",
    "\n",
    "        if other_norm == 0:\n",
    "            continue\n",
    "\n",
    "        similarities[other_word] = cosine_similarity(word_vector, other_vector)\n",
    "\n",
    "    return sorted(similarities.items(), key=lambda x: x[1], reverse=True)[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('мвд', 1.0),\n",
       " ('фсб', 0.76623964),\n",
       " ('кгб', 0.7264482),\n",
       " ('мгб', 0.69483584),\n",
       " ('гувд', 0.68139136),\n",
       " ('нквд', 0.6729191),\n",
       " ('госбезопасности', 0.6632358),\n",
       " ('увд', 0.6568187),\n",
       " ('гру', 0.64401966),\n",
       " ('прокуратуры', 0.6382184)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ineffective_most_similiar(navec_model, \"мвд\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = navec_model.pq.dim\n",
    "gensim_from_navec = gensim.models.KeyedVectors(vector_size)\n",
    "words, vectors = [], []\n",
    "for word in navec_model.vocab.words:\n",
    "    vec = navec_model[word]\n",
    "    if np.linalg.norm(vec) > 0:\n",
    "        words.append(word)\n",
    "        vectors.append(vec)\n",
    "\n",
    "gensim_from_navec.add_vectors(words, np.array(vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть ощущение, что вектора из navec и rusvector больше склонны показывать функциональную близость - т.е. слова, которые являются почти синонимами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим на каждом виде эмбеддингов модель логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(\n",
    "    data: pd.DataFrame,\n",
    "    emb_model: gensim.models.Word2Vec,\n",
    "    use_tag: bool = False,\n",
    "    is_kv: bool = False,\n",
    "    emb_dim: int = 300,\n",
    ") -> np.ndarray:\n",
    "    if use_tag:\n",
    "        morph = pymorphy3.MorphAnalyzer()\n",
    "    X = np.empty((0, emb_dim))\n",
    "    for text in data[\"filtered_text\"].values:\n",
    "        if use_tag:\n",
    "            pos_tags = [morph.parse(word)[0].tag.POS for word in text.split(\" \")]\n",
    "        avg_emb = np.empty((0, emb_dim))\n",
    "        for i, token in enumerate(text.split(\" \")):\n",
    "            token = f\"{token}_{pos_tags[i]}\" if use_tag else token\n",
    "            embs_storage = emb_model if is_kv else emb_model.wv\n",
    "            if token in embs_storage:\n",
    "                emb = embs_storage[token]\n",
    "                avg_emb = np.vstack((avg_emb, emb))\n",
    "        if len(avg_emb) > 0:\n",
    "            avg_emb = np.mean(avg_emb, axis=0).reshape(1, emb_dim)\n",
    "        else:\n",
    "            avg_emb = np.zeros((1, emb_dim))\n",
    "        X = np.vstack((X, avg_emb))\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_train_features = create_features(train_df, model, emb_dim=250)\n",
    "rusvec_train_features = create_features(\n",
    "    train_df, rusvec_model, use_tag=True, is_kv=True, emb_dim=300\n",
    ")\n",
    "navec_train_features = create_features(\n",
    "    train_df, gensim_from_navec, is_kv=True, emb_dim=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fpath, features in zip(\n",
    "    [\"custom_train\", \"rusvec_train\", \"navec_train\"],\n",
    "    [custom_train_features, rusvec_train_features, navec_train_features],\n",
    "):\n",
    "    with open(f\"../data/hw2/{fpath}.npy\", \"wb\") as f:\n",
    "        np.save(f, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_val_features = create_features(val_df, model, emb_dim=250)\n",
    "rusvec_val_features = create_features(\n",
    "    val_df, rusvec_model, use_tag=True, is_kv=True, emb_dim=300\n",
    ")\n",
    "navec_val_features = create_features(val_df, gensim_from_navec, is_kv=True, emb_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_test_features = create_features(test_df, model, emb_dim=250)\n",
    "rusvec_test_features = create_features(\n",
    "    test_df, rusvec_model, use_tag=True, is_kv=True, emb_dim=300\n",
    ")\n",
    "navec_test_features = create_features(\n",
    "    test_df, gensim_from_navec, is_kv=True, emb_dim=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logreg(X: np.ndarray, y: np.ndarray) -> LogisticRegression:\n",
    "    logreg = LogisticRegression(max_iter=2000)\n",
    "    logreg.fit(X, y)\n",
    "    return logreg\n",
    "\n",
    "\n",
    "y = train_df[\"label\"].values\n",
    "# custom_fs_logreg = train_logreg(custom_train_features, y)\n",
    "rusvec_fs_logreg = train_logreg(rusvec_train_features, y)\n",
    "# navec_fs_logreg = train_logreg(navec_train_features, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   69-я параллель       0.83      0.19      0.31       103\n",
      "       Библиотека       0.00      0.00      0.00         5\n",
      "           Бизнес       0.51      0.12      0.19       601\n",
      "      Бывший СССР       0.73      0.65      0.69      4333\n",
      "              Дом       0.76      0.70      0.73      1764\n",
      "         Из жизни       0.57      0.47      0.52      2241\n",
      "   Интернет и СМИ       0.65      0.56      0.60      3625\n",
      "             Крым       0.71      0.09      0.16        54\n",
      "    Культпросвет        0.00      0.00      0.00        28\n",
      "         Культура       0.81      0.81      0.81      4366\n",
      "          Легпром       0.00      0.00      0.00         9\n",
      "              Мир       0.73      0.79      0.76     11092\n",
      "  Наука и техника       0.75      0.75      0.75      4303\n",
      "      Путешествия       0.69      0.42      0.53       520\n",
      "           Россия       0.70      0.79      0.74     13015\n",
      "Силовые структуры       0.50      0.21      0.29      1590\n",
      "            Спорт       0.95      0.95      0.95      5227\n",
      "         Ценности       0.81      0.71      0.76       630\n",
      "        Экономика       0.76      0.82      0.79      6454\n",
      "\n",
      "         accuracy                           0.74     59960\n",
      "        macro avg       0.60      0.48      0.50     59960\n",
      "     weighted avg       0.73      0.74      0.73     59960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rusvec_vp = rusvec_fs_logreg.predict(rusvec_train_features)\n",
    "print(classification_report(train_df[\"label\"].values, rusvec_vp, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   69-я параллель       0.90      0.25      0.39       103\n",
      "       Библиотека       0.00      0.00      0.00         5\n",
      "           Бизнес       0.58      0.21      0.31       601\n",
      "      Бывший СССР       0.81      0.82      0.82      4333\n",
      "              Дом       0.85      0.80      0.82      1764\n",
      "         Из жизни       0.67      0.61      0.64      2241\n",
      "   Интернет и СМИ       0.76      0.70      0.73      3625\n",
      "             Крым       1.00      0.09      0.17        54\n",
      "    Культпросвет        0.00      0.00      0.00        28\n",
      "         Культура       0.87      0.88      0.88      4366\n",
      "          Легпром       0.00      0.00      0.00         9\n",
      "              Мир       0.80      0.84      0.82     11092\n",
      "  Наука и техника       0.84      0.84      0.84      4303\n",
      "      Путешествия       0.77      0.61      0.68       520\n",
      "           Россия       0.77      0.83      0.80     13015\n",
      "Силовые структуры       0.63      0.35      0.45      1590\n",
      "            Спорт       0.96      0.97      0.96      5227\n",
      "         Ценности       0.89      0.83      0.86       630\n",
      "        Экономика       0.82      0.86      0.84      6454\n",
      "\n",
      "         accuracy                           0.81     59960\n",
      "        macro avg       0.68      0.55      0.58     59960\n",
      "     weighted avg       0.81      0.81      0.81     59960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "custom_vp = custom_fs_logreg.predict(custom_train_features)\n",
    "print(classification_report(train_df[\"label\"].values, custom_vp, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rusvec_vp = rusvec_fs_logreg.predict(rusvec_val_features)\n",
    "print(classification_report(val_df[\"label\"].values, rusvec_vp, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "navec_vp = navec_fs_logreg.predict(navec_val_features)\n",
    "print(classification_report(val_df[\"label\"].values, navec_vp, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
